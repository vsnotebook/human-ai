侧边栏的缅甸语同声传译、语音转文本、文本转语音 都 选择一个比较好的图标。

侧边栏添加“缅甸语同声传译“



系统主打缅甸语同声传译功能。
系统默认只显示“我的主页”、“缅甸语同声传译”。
你设计一个方案，用户如果想查看其他功能，就显示其他按钮。




设计一个方案，默认只显示"我的主页"和"缅甸语同声传译"这两个主要功能，其他功能通过一个"更多功能"的下拉菜单来展示。这样既突出了系统的主打功能，又保留了其他功能的可访问性。

创建模板文件 myanmar_interpretation.html ，专注于移动端友好的 UI 设计
请引入 tailwindcss CDN 来完成，减少编写 style 样式


请引入 tailwindcss CDN 来完成，而不是编写 style 样式


# myanmar_interpretation.html
缅甸语同声传译“功能这是系统最核心的功能。UI设计必须非常吸引客户。
实现同声传译功能。中文转缅甸语。
支持移动端的友好显示。该功能主要用于手机端。
请引入 tailwindcss CDN 来完成，减少编写 style 样式


上面的截图，是我直接从手机截取的同声传译图片。这是我要求的手机端的效果。

我明白了，您想要参考截图中的手机端翻译界面设计。我会根据截图调整当前的HTML代码，使其更接近手机应用的外观和交互体验。主要需要做以下改动：

1. 简化顶部导航栏
2. 调整输入框样式
3. 添加语言选择按钮
4. 修改底部语音输入按钮的样式

还是要修改。就像用微信聊天，说中文的左对齐，下面是翻译的缅甸语。 说缅甸文的由对齐，下面是中文。


- 重新设计了消息展示区域，采用类似微信的气泡样式
- 中文消息左对齐，使用白色背景
- 缅甸语消息右对齐，使用蓝色背景
- 每条消息都包含原文和译文
- 底部按钮改为"按住说话"模式
- 添加了消息自动滚动功能
- 优化了移动端触摸事件处理
- 简化了界面，移除了不必要的控件

样式还要美化下。 屏幕的背景都是白色。中文消息使用偏灰色。 不需要默认的对话。
- 将整体背景改为纯白色
- 移除了默认的对话示例
- 中文消息气泡改用灰色背景（bg-gray-100）
- 优化了顶部导航栏，添加了底部边框
- 美化了底部按钮样式，添加了悬停效果
- 调整了消息气泡的间距和阴影效果
- 优化了文字颜色对比度

我回退代码到了上一个版本。

不改变现有的页面展示的前提下，你现在实现调用后台的翻译接口。
参考 voice_translate.html 调用的后台接口。
因为后台对音频流格式有齐要求，因此有如下要求：
1. 设置录音参数：单声道、16kHz采样率、16位采样大小
2. 使用PCM音频格式编码器进行录音
3. 添加了将AudioBuffer转换为WAV格式的函数
4. 在录音停止时，将录音数据转换为WAV格式后再发送到服务器

添加一个函数执行计时器。方便我查询函数的执行时间。
实时音频翻译，有3个步骤。1. 语音识别。# 2. 文本翻译。# 3. 文本转语音。 3个步骤。可以识别完成之后，就马上返回前端。翻译完成，马上返回前端。

myanmar_interpretation.html 参考 ws_server.py  参考ws_server.py ，使用websocket实现实时语音识别。

## 主要修改说明
1. 添加WebSocket连接功能 ：

   - 新增了 initWebSocket 函数，用于建立与后端的WebSocket连接
   - 根据用户选择的语言（中文或缅甸语）初始化不同的识别模式
2. 实时音频数据处理 ：

   - 修改了 mediaRecorder 的配置，设置较小的 timeslice (100ms)，使音频数据能够实时发送
   - 在 ondataavailable 事件中，将音频数据直接通过WebSocket发送到服务器
3. 实时识别结果处理 ：

   - 添加了WebSocket的 onmessage 事件处理，接收服务器返回的实时识别结果
   - 当收到句子结束标志时，发送翻译请求
4. 翻译请求处理 ：

   - 新增了 sendTranslationRequest 函数，用于发送文本翻译请求
   - 保留了原有的录音处理逻辑作为备用方案
这个实现方案利用WebSocket实现了实时语音识别，可以在用户说话的同时进行识别，并在句子结束时自动发送翻译请求，提供更流畅的用户体验。

注意：你需要在后端添加一个新的API端点 /myanmar-interpretation/text 来处理文本翻译请求。

用户在前端，怎么开启websocket进行同声传译。

参考audio_recorder.js  index.html  recorder_worklet.js  server.py 修改 ws_speech.py  myanmar_interpretation.html。 目的是使用websocket实现阿里云的实时语音识别。

分析同声传译代码。
当前的处理逻辑是，调用/myanmar-interpretation/text接口。 该接口会完成文本翻译和语音合成。
现在修改为，调用/myanmar-interpretation/text接口，只对文本翻译。然后自动调用/text-to-speech语音合成接口。
然后前端自动播放语音。同时在翻译文本的最后生成一个语音播放图标。用户可以点击就可以播放


返回语音合成后，有一个播放的图标，用户可以点击播放。要美观和现代。
1、翻译结果返回后，自动发起语音合成。
2、不要移除自动播放。
前端收到翻译结果，要立即自动发起语音合成。
1、图标位置

